# 2.5 Regresión Lineal (Linear Regression)

## Notas

Modelo para resolver tareas de regresión, cuyo objetivo es ajustar una línea para los datos y realizar predicciones sobre nuevos valores. La entrada de este modelo es la **matriz de características** `X` y se obtiene un **vector de predicciones** `y`, buscando aproximarse lo más posible a los valores `y` **reales**. La fórmula de regresión lineal es la suma del término de sesgo \( $w_0$ \), que se refiere a las predicciones si no hay información, y cada uno de los valores de las características multiplicado por sus pesos correspondientes como \( $x_{i1} \cdot w_1 + x_{i2} \cdot w_2 + ... + x_{in} \cdot w_n$ \).

Por lo tanto, la fórmula de regresión lineal simple se ve así:

$g(x_i) = w_0 + x_{i1} \cdot w_1 + x_{i2} \cdot w_2 + ... + x_{in} \cdot w_n$. 

Y esto se puede simplificar aún más:

$g(x_i) = w_0 + \displaystyle\sum_{j=1}^{n} w_j \cdot x_{ij}$


enfocándonos solo en el dataframe para el entrenamiento, df_train,  buscamos un vector con las características de un auto

```python
df_train.iloc[10]
```

tomaremos 

    engine_hp = 453.0
    city_mpg = 11
    popularity = 86


```python
[453,11,86]
```

implementando el modelo


$g(x_{i}) = w_{0} + {w1.x_{i1}} + {w2.x_{i2}} + {w_{n}.x_{in}}$



donde 

w0 es el término de sesgo, es decir, el precio que predecimos sin nada de información

w es un vector con el peso de cada característica

```python
w0 = 0
w = [1, 1, 1]
```

Regresión Lineal Simple (Simple Linear Regression)


```python
def linear_regression(xi):
    # longitud de xi debe ser igual al de w 
    n = len(xi)

    pred = W0

    for j in arange(n)
        pred = pred + w[j] * xi[j]

    return pred
```

probar con w0 distinto de 0 y nuevos pesos en el vector w

```python
w0 = 7.17
w = [0.01, 0.04, 0.002]
```

nuevamente lo que hace es

    7.17 + 453x0.01 + 11x0.04 + 86x0.002 = 12.3

 - *7.17* => es el término de sesgo, es el logaritmo del precio 

 - *453x0.01* => caballos de fuerza por su peso

 - *11x0.04* => millas por galón de combustible por su peso

- *86x0.002* => cantidad de mensiones del vehiculo por su peso, popularidad

- *12.312* =>  la predicción obtenida del precio expresado en logaritmo


Si observamos la parte $\displaystyle\sum_{j=1}^{n} w_j \cdot x_{ij}$ de la ecuación anterior, sabemos que se trata de una multiplicación vector-vector. Por lo tanto, podemos reescribir la ecuación como $g(x_i) = w_0 + x_i^T \cdot w$

Debemos asegurarnos de que el resultado se muestre en la escala sin transformar mediante la función inversa `exp()`.

Deshacer el logaritmo para ver el precio anexando - 1 en contrapartida al + 1 que se hizo al hacer el logaritmo

```python
np.exp(12.312) - 1
```

también hay un método para no tener que agregar el -1 manualmente


```python
np.expm1(12.312)
```

 y da com predicción de precio $ 222347.2221101062

si aplicamos el logaritmo nuevamente deberíamos obtener nuevamente la predicción 12.312


```python
np.log1p(222347.2221101062)
```

El código completo de este proyecto está disponible en [este cuaderno Jupyter](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/chapter-02-car-price/02-carprice.ipynb).


# 2.4 Configuración del marco de validación(validation framework)


Dividir el dataframe en 3 partes:

- TRAIN => 60%
- VALIDATION => 20%
- TEST => 20%

cada una tendrá su matriz de características "X" y la variable objetivo "y"

vemos el tamaño del dataframe y lo dividimos

```python
n = len(df)

n_val = int(n * 0.2)
n_test = int(n * 0.2)
n_train = n - n_val - n_test
```
n_val con 2382 filas
n_test con 2382 filas
n_train con 7150 filas

Ahora que sabemos que tamaño tendrá cada uno sacaremos esa parte del dataframe utilizando "iloc"


```python
df_val = df.iloc[:n_val]
df_test = df.iloc[n_val:n_val+n_test]
df_train = df.iloc[n_train:n_val+n_test]
```


funciona muy bien sin embargo es necesario mezclar los registros en el dataframe antes para asegurarnos que los 3 contengan diversidad de datos y evitar bloques datos queden atrapados en un mismo dataframe, ejemplo: de una misma marca, año, etc

disponemos la división del dataframe acorde como se planteó al principio (60%, 20%, 20%)


```python
df_train = df.iloc[:n_train]
df_val = df.iloc[n_train:n_train+n_val]
df_test = df.iloc[n_train+n_val:]
```

generamos una secuencia de números con la cantidad de registros y lo guardamos en una variable que se comportará como un índice


```python
idx = np.arange(n)
```

lo mezclamos


```python
np.random.shuffle(idx)
```

para verlo:


```python
idx[n_train:]
```
o

```python
idx[n_train:n_train+n_val]
```
o

```python
idx[n_train+n_val:]
```


ahora ya podemos usar los índices para que, en vez de obtener las filas con los datos directamente, las obtengamos mediante ellos


```python
df_train = df.iloc[idx[:n_train]]
df_val = df.iloc[idx[n_train:n_train+n_val]]
df_test = df.iloc[n_train+n_val:]
```

para que sea posible reporoducir lo anterior y de siempre el mismo resultado es necesario establecer una "semilla" en el método random 

generamos el índice, establecemos semilla y mezclamos de nuevo


```python
idx = np.arange(n)
np.random.seed(2)
np.random.shuffle(idx)
```

volvemos a armar los dataframes


```python
df_train = df.iloc[idx[:n_train]]
df_val = df.iloc[idx[n_train:n_train+n_val]]
df_test = df.iloc[n_train+n_val:]
```

verificamos visualmente


```python
df_train.head()
```

verificamos el tamaño


```python
len(df_train),len(df_val),len(df_test)
```

los dataframes tienen el índice original con el que fueron creados y a veces no es conveniente por lo que podemos resetearlos

```python
df_train = df_train.reset_index(drop=True)
df_val = df_val.reset_index(drop=True)
df_test = df_test.reset_index(drop=True)
```

ahora necesitamos transormar la variable y de que usaremos para hacer la matriz de caracterísitcas X de cada dataframe

aplicar el logaritmo+1 a y y salvarla

```python
y_train = np.log1p(df_train.msrp.values)
y_val = np.log1p(df_val.msrp.values)
y_test = np.log1p(df_test.msrp.values)
```

podemos verificar que la cantidades sean correctas

```python
len(y_train),len(y_val),len(y_test)
```

y finalmente removemos la variable MSRP de los dataframes para evitar utilizarla accidentalmente ya que de hacerlo es posible que la predecciones sean perfectamente iguales y perderíamos mucho tiempo en encontrar la causa


```python
del df_train['msrp']
del df_val['msrp']
del df_test['msrp']
```


El código completo de este proyecto está disponible en [este cuaderno Jupyter](https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/chapter-02-car-price/02-carprice.ipynb).